{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "\n",
    "if not os.path.exists('./img'):\n",
    "    os.mkdir('./img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_img(x):\n",
    "    out = 0.5 * (x + 1)\n",
    "    out = out.clamp(0, 1)\n",
    "    out = out.view(-1, 1, 28, 28)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "num_epoch = 100\n",
    "z_dimension = 100\n",
    "\n",
    "# Image processing\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "])\n",
    "# MNIST dataset\n",
    "mnist = datasets.MNIST(\n",
    "    root='./data/', train=True, transform=img_transform, download=True)\n",
    "# Data loader\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    dataset=mnist, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "class discriminator(nn.Module):\n",
    "    \"\"\"\n",
    "    判别网络事实上就是一个二分类的网络，分辨图片的真伪\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(discriminator, self).__init__()\n",
    "        self.dis = nn.Sequential(\n",
    "            nn.Linear(784, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.LeakyReLU(0.2), nn.Linear(256, 1), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dis(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Generator\n",
    "class generator(nn.Module):\n",
    "    \"\"\"\n",
    "    生成网络随机一个向量生成一个图片\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(generator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            nn.Linear(100, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 256), nn.ReLU(True), nn.Linear(256, 784), nn.Tanh())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.gen(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangxinyang848/anaconda3/envs/jiang/lib/python3.5/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([128])) that is different to the input size (torch.Size([128, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n",
      "/home/jiangxinyang848/anaconda3/envs/jiang/lib/python3.5/site-packages/ipykernel_launcher.py:53: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/100], d_loss: 0.121998, g_loss: 3.546974 D real: 0.977048, D fake: 0.091577\n",
      "Epoch [0/100], d_loss: 0.058318, g_loss: 4.290877 D real: 0.985306, D fake: 0.042083\n",
      "Epoch [0/100], d_loss: 0.161965, g_loss: 5.152973 D real: 0.965903, D fake: 0.102542\n",
      "Epoch [0/100], d_loss: 0.001653, g_loss: 8.397080 D real: 0.999845, D fake: 0.001493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiangxinyang848/anaconda3/envs/jiang/lib/python3.5/site-packages/torch/nn/functional.py:1594: UserWarning: Using a target size (torch.Size([96])) that is different to the input size (torch.Size([96, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], d_loss: 0.117615, g_loss: 5.177507 D real: 0.957375, D fake: 0.055432\n",
      "Epoch [1/100], d_loss: 0.028472, g_loss: 6.449814 D real: 0.985970, D fake: 0.012861\n",
      "Epoch [1/100], d_loss: 0.241403, g_loss: 5.855880 D real: 0.924284, D fake: 0.067448\n",
      "Epoch [1/100], d_loss: 0.127386, g_loss: 7.272000 D real: 0.959430, D fake: 0.046443\n",
      "Epoch [2/100], d_loss: 0.572582, g_loss: 4.427216 D real: 0.898730, D fake: 0.238263\n",
      "Epoch [2/100], d_loss: 0.489846, g_loss: 4.319398 D real: 0.872898, D fake: 0.158038\n",
      "Epoch [2/100], d_loss: 0.297053, g_loss: 5.099032 D real: 0.936843, D fake: 0.107696\n",
      "Epoch [2/100], d_loss: 0.856211, g_loss: 3.953827 D real: 0.848682, D fake: 0.348639\n",
      "Epoch [3/100], d_loss: 0.270003, g_loss: 5.351149 D real: 0.926315, D fake: 0.025403\n",
      "Epoch [3/100], d_loss: 0.379847, g_loss: 4.761645 D real: 0.882656, D fake: 0.122177\n",
      "Epoch [3/100], d_loss: 3.827452, g_loss: 0.856467 D real: 0.295213, D fake: 0.658173\n",
      "Epoch [3/100], d_loss: 1.200500, g_loss: 2.176889 D real: 0.733944, D fake: 0.428465\n",
      "Epoch [4/100], d_loss: 0.507822, g_loss: 2.358276 D real: 0.874687, D fake: 0.262675\n",
      "Epoch [4/100], d_loss: 1.426314, g_loss: 1.918471 D real: 0.653277, D fake: 0.462313\n",
      "Epoch [4/100], d_loss: 0.972233, g_loss: 2.893918 D real: 0.726242, D fake: 0.268457\n",
      "Epoch [4/100], d_loss: 0.209579, g_loss: 3.191013 D real: 0.908081, D fake: 0.069691\n",
      "Epoch [5/100], d_loss: 0.265097, g_loss: 2.906657 D real: 0.894208, D fake: 0.070589\n",
      "Epoch [5/100], d_loss: 1.727185, g_loss: 2.473335 D real: 0.619278, D fake: 0.269059\n",
      "Epoch [5/100], d_loss: 0.999613, g_loss: 2.982082 D real: 0.803249, D fake: 0.309919\n",
      "Epoch [5/100], d_loss: 1.147963, g_loss: 2.277588 D real: 0.794433, D fake: 0.300883\n",
      "Epoch [6/100], d_loss: 0.958323, g_loss: 3.126487 D real: 0.695670, D fake: 0.112212\n",
      "Epoch [6/100], d_loss: 0.579068, g_loss: 3.192152 D real: 0.836596, D fake: 0.105872\n",
      "Epoch [6/100], d_loss: 0.215763, g_loss: 4.567951 D real: 0.946403, D fake: 0.056106\n",
      "Epoch [6/100], d_loss: 0.166304, g_loss: 4.714721 D real: 0.955553, D fake: 0.086882\n",
      "Epoch [7/100], d_loss: 0.318058, g_loss: 4.450749 D real: 0.900064, D fake: 0.076094\n",
      "Epoch [7/100], d_loss: 0.181426, g_loss: 4.947215 D real: 0.917296, D fake: 0.040481\n",
      "Epoch [7/100], d_loss: 0.219507, g_loss: 3.383530 D real: 0.910320, D fake: 0.067227\n",
      "Epoch [7/100], d_loss: 0.649896, g_loss: 2.990434 D real: 0.823011, D fake: 0.211994\n",
      "Epoch [8/100], d_loss: 1.186864, g_loss: 3.080366 D real: 0.630955, D fake: 0.127021\n",
      "Epoch [8/100], d_loss: 0.413404, g_loss: 3.987215 D real: 0.898576, D fake: 0.104687\n",
      "Epoch [8/100], d_loss: 1.029864, g_loss: 2.180621 D real: 0.724146, D fake: 0.270260\n",
      "Epoch [8/100], d_loss: 0.609264, g_loss: 2.967552 D real: 0.794208, D fake: 0.123825\n",
      "Epoch [9/100], d_loss: 0.302897, g_loss: 5.019897 D real: 0.920161, D fake: 0.102211\n",
      "Epoch [9/100], d_loss: 0.323088, g_loss: 3.331378 D real: 0.907415, D fake: 0.120840\n",
      "Epoch [9/100], d_loss: 0.329897, g_loss: 3.339093 D real: 0.903686, D fake: 0.141487\n",
      "Epoch [9/100], d_loss: 0.479089, g_loss: 2.631929 D real: 0.829930, D fake: 0.110683\n",
      "Epoch [10/100], d_loss: 0.286182, g_loss: 4.009117 D real: 0.886203, D fake: 0.068500\n",
      "Epoch [10/100], d_loss: 0.541720, g_loss: 2.851789 D real: 0.870177, D fake: 0.185485\n",
      "Epoch [10/100], d_loss: 0.135393, g_loss: 3.780466 D real: 0.952448, D fake: 0.063275\n",
      "Epoch [10/100], d_loss: 0.392818, g_loss: 2.495080 D real: 0.874958, D fake: 0.125496\n",
      "Epoch [11/100], d_loss: 0.390813, g_loss: 3.037656 D real: 0.875817, D fake: 0.074903\n",
      "Epoch [11/100], d_loss: 0.472658, g_loss: 3.286951 D real: 0.843993, D fake: 0.102209\n",
      "Epoch [11/100], d_loss: 0.854239, g_loss: 3.784164 D real: 0.852826, D fake: 0.293967\n",
      "Epoch [11/100], d_loss: 0.690114, g_loss: 4.369739 D real: 0.763104, D fake: 0.074332\n",
      "Epoch [12/100], d_loss: 0.420160, g_loss: 2.975266 D real: 0.863311, D fake: 0.095807\n",
      "Epoch [12/100], d_loss: 0.697879, g_loss: 4.095780 D real: 0.891198, D fake: 0.282285\n",
      "Epoch [12/100], d_loss: 0.951769, g_loss: 2.311792 D real: 0.836503, D fake: 0.407959\n",
      "Epoch [12/100], d_loss: 0.928081, g_loss: 2.321815 D real: 0.743120, D fake: 0.198217\n",
      "Epoch [13/100], d_loss: 0.731438, g_loss: 3.083542 D real: 0.793685, D fake: 0.217907\n",
      "Epoch [13/100], d_loss: 0.513684, g_loss: 2.682680 D real: 0.792358, D fake: 0.093632\n",
      "Epoch [13/100], d_loss: 0.394093, g_loss: 3.067147 D real: 0.852718, D fake: 0.127785\n",
      "Epoch [13/100], d_loss: 0.328446, g_loss: 2.947845 D real: 0.907897, D fake: 0.140744\n",
      "Epoch [14/100], d_loss: 0.200079, g_loss: 3.128978 D real: 0.930859, D fake: 0.092310\n",
      "Epoch [14/100], d_loss: 0.377971, g_loss: 2.951738 D real: 0.863249, D fake: 0.069978\n",
      "Epoch [14/100], d_loss: 0.288763, g_loss: 3.711828 D real: 0.889579, D fake: 0.075476\n",
      "Epoch [14/100], d_loss: 0.268149, g_loss: 4.407402 D real: 0.915886, D fake: 0.094327\n",
      "Epoch [15/100], d_loss: 0.430979, g_loss: 2.847279 D real: 0.891829, D fake: 0.138466\n",
      "Epoch [15/100], d_loss: 0.720504, g_loss: 2.570553 D real: 0.857084, D fake: 0.301082\n",
      "Epoch [15/100], d_loss: 0.321057, g_loss: 3.540047 D real: 0.938682, D fake: 0.131649\n",
      "Epoch [15/100], d_loss: 0.199077, g_loss: 3.515773 D real: 0.909578, D fake: 0.041466\n",
      "Epoch [16/100], d_loss: 0.313959, g_loss: 3.440297 D real: 0.918180, D fake: 0.111747\n",
      "Epoch [16/100], d_loss: 0.476738, g_loss: 4.564980 D real: 0.810777, D fake: 0.050165\n",
      "Epoch [16/100], d_loss: 0.548778, g_loss: 3.413920 D real: 0.827365, D fake: 0.109838\n",
      "Epoch [16/100], d_loss: 0.281642, g_loss: 4.698238 D real: 0.914664, D fake: 0.105439\n",
      "Epoch [17/100], d_loss: 0.376666, g_loss: 3.772158 D real: 0.847663, D fake: 0.065144\n",
      "Epoch [17/100], d_loss: 0.281853, g_loss: 4.939764 D real: 0.916526, D fake: 0.083430\n",
      "Epoch [17/100], d_loss: 0.242762, g_loss: 3.937135 D real: 0.925957, D fake: 0.078534\n",
      "Epoch [17/100], d_loss: 0.286651, g_loss: 4.050989 D real: 0.882170, D fake: 0.058348\n",
      "Epoch [18/100], d_loss: 0.601539, g_loss: 3.219059 D real: 0.801939, D fake: 0.069263\n",
      "Epoch [18/100], d_loss: 0.410301, g_loss: 3.038987 D real: 0.865783, D fake: 0.117819\n",
      "Epoch [18/100], d_loss: 0.475404, g_loss: 3.284755 D real: 0.881684, D fake: 0.182285\n",
      "Epoch [18/100], d_loss: 0.498233, g_loss: 3.151284 D real: 0.834893, D fake: 0.113540\n",
      "Epoch [19/100], d_loss: 0.332287, g_loss: 3.056263 D real: 0.901028, D fake: 0.120935\n",
      "Epoch [19/100], d_loss: 0.666839, g_loss: 2.742725 D real: 0.823504, D fake: 0.213043\n",
      "Epoch [19/100], d_loss: 0.589154, g_loss: 1.867254 D real: 0.841137, D fake: 0.164994\n",
      "Epoch [19/100], d_loss: 0.444395, g_loss: 2.719079 D real: 0.834382, D fake: 0.067471\n",
      "Epoch [20/100], d_loss: 0.350174, g_loss: 4.098921 D real: 0.887859, D fake: 0.114363\n",
      "Epoch [20/100], d_loss: 0.523253, g_loss: 4.600523 D real: 0.835714, D fake: 0.094267\n",
      "Epoch [20/100], d_loss: 0.598139, g_loss: 3.924557 D real: 0.834006, D fake: 0.129461\n",
      "Epoch [20/100], d_loss: 0.238057, g_loss: 4.635109 D real: 0.905586, D fake: 0.069351\n",
      "Epoch [21/100], d_loss: 0.752534, g_loss: 4.481405 D real: 0.759498, D fake: 0.063957\n",
      "Epoch [21/100], d_loss: 0.836301, g_loss: 2.170834 D real: 0.862530, D fake: 0.320305\n",
      "Epoch [21/100], d_loss: 0.424718, g_loss: 4.402477 D real: 0.880783, D fake: 0.123241\n",
      "Epoch [21/100], d_loss: 0.597140, g_loss: 3.725313 D real: 0.796412, D fake: 0.150933\n",
      "Epoch [22/100], d_loss: 0.600779, g_loss: 3.713211 D real: 0.819372, D fake: 0.131118\n",
      "Epoch [22/100], d_loss: 0.379614, g_loss: 4.239814 D real: 0.852436, D fake: 0.068848\n",
      "Epoch [22/100], d_loss: 0.564826, g_loss: 3.681248 D real: 0.823218, D fake: 0.097889\n",
      "Epoch [22/100], d_loss: 0.440058, g_loss: 3.706909 D real: 0.890991, D fake: 0.111580\n",
      "Epoch [23/100], d_loss: 0.381666, g_loss: 5.691986 D real: 0.879351, D fake: 0.050686\n",
      "Epoch [23/100], d_loss: 0.345740, g_loss: 4.200753 D real: 0.894337, D fake: 0.108805\n",
      "Epoch [23/100], d_loss: 0.418044, g_loss: 5.392431 D real: 0.946752, D fake: 0.207775\n",
      "Epoch [23/100], d_loss: 0.381570, g_loss: 2.661542 D real: 0.877181, D fake: 0.117737\n",
      "Epoch [24/100], d_loss: 0.475133, g_loss: 2.976856 D real: 0.878291, D fake: 0.147448\n",
      "Epoch [24/100], d_loss: 0.241903, g_loss: 3.578839 D real: 0.947026, D fake: 0.130370\n",
      "Epoch [24/100], d_loss: 0.433228, g_loss: 3.730728 D real: 0.846473, D fake: 0.086421\n",
      "Epoch [24/100], d_loss: 0.259804, g_loss: 3.909369 D real: 0.918280, D fake: 0.087427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], d_loss: 0.442195, g_loss: 2.711858 D real: 0.933837, D fake: 0.217963\n",
      "Epoch [25/100], d_loss: 0.510269, g_loss: 2.995680 D real: 0.845244, D fake: 0.090710\n",
      "Epoch [25/100], d_loss: 0.450366, g_loss: 3.307637 D real: 0.917693, D fake: 0.207150\n",
      "Epoch [25/100], d_loss: 0.368705, g_loss: 3.072907 D real: 0.859574, D fake: 0.076115\n",
      "Epoch [26/100], d_loss: 0.366540, g_loss: 3.157058 D real: 0.930553, D fake: 0.177950\n",
      "Epoch [26/100], d_loss: 0.440447, g_loss: 3.956893 D real: 0.877068, D fake: 0.161179\n",
      "Epoch [26/100], d_loss: 0.659666, g_loss: 4.350977 D real: 0.820283, D fake: 0.146988\n",
      "Epoch [26/100], d_loss: 0.278245, g_loss: 3.039406 D real: 0.933202, D fake: 0.134388\n",
      "Epoch [27/100], d_loss: 0.385205, g_loss: 3.183555 D real: 0.902588, D fake: 0.116742\n",
      "Epoch [27/100], d_loss: 0.489432, g_loss: 3.307326 D real: 0.825440, D fake: 0.104576\n",
      "Epoch [27/100], d_loss: 0.382388, g_loss: 3.259119 D real: 0.879281, D fake: 0.100267\n",
      "Epoch [27/100], d_loss: 0.586138, g_loss: 3.190042 D real: 0.880808, D fake: 0.206054\n",
      "Epoch [28/100], d_loss: 0.464192, g_loss: 3.946034 D real: 0.847592, D fake: 0.137806\n",
      "Epoch [28/100], d_loss: 0.555687, g_loss: 3.909316 D real: 0.886129, D fake: 0.219973\n",
      "Epoch [28/100], d_loss: 0.248489, g_loss: 3.455989 D real: 0.924731, D fake: 0.105521\n",
      "Epoch [28/100], d_loss: 0.322113, g_loss: 4.096460 D real: 0.911870, D fake: 0.119860\n",
      "Epoch [29/100], d_loss: 0.623832, g_loss: 3.335280 D real: 0.816239, D fake: 0.151386\n",
      "Epoch [29/100], d_loss: 0.413295, g_loss: 5.182862 D real: 0.851477, D fake: 0.021849\n",
      "Epoch [29/100], d_loss: 0.321544, g_loss: 3.132189 D real: 0.893986, D fake: 0.112177\n",
      "Epoch [29/100], d_loss: 0.343598, g_loss: 4.314466 D real: 0.873317, D fake: 0.082409\n",
      "Epoch [30/100], d_loss: 0.732346, g_loss: 2.387476 D real: 0.786736, D fake: 0.177473\n",
      "Epoch [30/100], d_loss: 0.483465, g_loss: 2.751709 D real: 0.832319, D fake: 0.112136\n",
      "Epoch [30/100], d_loss: 0.397922, g_loss: 3.302381 D real: 0.876197, D fake: 0.151944\n",
      "Epoch [30/100], d_loss: 0.379649, g_loss: 3.893239 D real: 0.886319, D fake: 0.126995\n",
      "Epoch [31/100], d_loss: 0.409586, g_loss: 2.741581 D real: 0.852482, D fake: 0.094325\n",
      "Epoch [31/100], d_loss: 0.380982, g_loss: 4.036727 D real: 0.884556, D fake: 0.123055\n",
      "Epoch [31/100], d_loss: 0.504324, g_loss: 3.384817 D real: 0.926197, D fake: 0.233419\n",
      "Epoch [31/100], d_loss: 0.296648, g_loss: 2.918609 D real: 0.922763, D fake: 0.128335\n",
      "Epoch [32/100], d_loss: 0.328755, g_loss: 3.173158 D real: 0.931281, D fake: 0.172103\n",
      "Epoch [32/100], d_loss: 0.354523, g_loss: 3.360006 D real: 0.899891, D fake: 0.117966\n",
      "Epoch [32/100], d_loss: 0.363591, g_loss: 3.738650 D real: 0.887486, D fake: 0.114674\n",
      "Epoch [32/100], d_loss: 0.297640, g_loss: 4.617866 D real: 0.924574, D fake: 0.135897\n",
      "Epoch [33/100], d_loss: 0.463803, g_loss: 2.251753 D real: 0.849138, D fake: 0.127837\n",
      "Epoch [33/100], d_loss: 0.310723, g_loss: 4.124984 D real: 0.871821, D fake: 0.077513\n",
      "Epoch [33/100], d_loss: 0.595493, g_loss: 3.781878 D real: 0.871143, D fake: 0.169063\n",
      "Epoch [33/100], d_loss: 0.480390, g_loss: 3.978049 D real: 0.924001, D fake: 0.193990\n",
      "Epoch [34/100], d_loss: 0.346627, g_loss: 5.053954 D real: 0.907118, D fake: 0.123075\n",
      "Epoch [34/100], d_loss: 0.448100, g_loss: 3.816859 D real: 0.869482, D fake: 0.141548\n",
      "Epoch [34/100], d_loss: 0.517112, g_loss: 4.172263 D real: 0.809826, D fake: 0.068474\n",
      "Epoch [34/100], d_loss: 0.469012, g_loss: 3.604357 D real: 0.858537, D fake: 0.132739\n",
      "Epoch [35/100], d_loss: 0.610014, g_loss: 2.691983 D real: 0.842728, D fake: 0.200845\n",
      "Epoch [35/100], d_loss: 0.512335, g_loss: 2.562935 D real: 0.864142, D fake: 0.174902\n",
      "Epoch [35/100], d_loss: 0.340678, g_loss: 3.172657 D real: 0.918334, D fake: 0.161881\n",
      "Epoch [35/100], d_loss: 0.405122, g_loss: 3.002213 D real: 0.894907, D fake: 0.162123\n",
      "Epoch [36/100], d_loss: 0.433697, g_loss: 4.068128 D real: 0.841890, D fake: 0.120951\n",
      "Epoch [36/100], d_loss: 0.411511, g_loss: 3.636595 D real: 0.864935, D fake: 0.137225\n",
      "Epoch [36/100], d_loss: 0.363101, g_loss: 3.337436 D real: 0.887902, D fake: 0.099011\n",
      "Epoch [36/100], d_loss: 0.629895, g_loss: 3.425841 D real: 0.818135, D fake: 0.195523\n",
      "Epoch [37/100], d_loss: 0.560194, g_loss: 2.700883 D real: 0.805806, D fake: 0.140187\n",
      "Epoch [37/100], d_loss: 0.465388, g_loss: 2.988153 D real: 0.883146, D fake: 0.148472\n",
      "Epoch [37/100], d_loss: 0.389079, g_loss: 2.529474 D real: 0.874317, D fake: 0.103508\n",
      "Epoch [37/100], d_loss: 0.336024, g_loss: 3.363088 D real: 0.894286, D fake: 0.118283\n",
      "Epoch [38/100], d_loss: 0.510669, g_loss: 2.983115 D real: 0.820367, D fake: 0.096405\n",
      "Epoch [38/100], d_loss: 0.555076, g_loss: 2.901925 D real: 0.892014, D fake: 0.259681\n",
      "Epoch [38/100], d_loss: 0.344218, g_loss: 3.510701 D real: 0.887948, D fake: 0.122187\n",
      "Epoch [38/100], d_loss: 0.361256, g_loss: 2.754220 D real: 0.926710, D fake: 0.200220\n",
      "Epoch [39/100], d_loss: 0.485552, g_loss: 3.718835 D real: 0.805089, D fake: 0.080286\n",
      "Epoch [39/100], d_loss: 0.373565, g_loss: 3.990026 D real: 0.897335, D fake: 0.156195\n",
      "Epoch [39/100], d_loss: 0.321669, g_loss: 3.691652 D real: 0.920138, D fake: 0.137912\n",
      "Epoch [39/100], d_loss: 0.397105, g_loss: 2.981375 D real: 0.838230, D fake: 0.081722\n",
      "Epoch [40/100], d_loss: 0.551539, g_loss: 3.189975 D real: 0.875240, D fake: 0.201927\n",
      "Epoch [40/100], d_loss: 0.371336, g_loss: 3.541031 D real: 0.882013, D fake: 0.139602\n",
      "Epoch [40/100], d_loss: 0.687050, g_loss: 2.561704 D real: 0.901460, D fake: 0.304853\n",
      "Epoch [40/100], d_loss: 0.571006, g_loss: 2.964563 D real: 0.854086, D fake: 0.190418\n",
      "Epoch [41/100], d_loss: 0.480149, g_loss: 4.344588 D real: 0.812050, D fake: 0.090041\n",
      "Epoch [41/100], d_loss: 0.441360, g_loss: 3.223254 D real: 0.808530, D fake: 0.086712\n",
      "Epoch [41/100], d_loss: 0.442224, g_loss: 3.256232 D real: 0.902359, D fake: 0.163165\n",
      "Epoch [41/100], d_loss: 0.403965, g_loss: 2.944058 D real: 0.851573, D fake: 0.114453\n",
      "Epoch [42/100], d_loss: 0.442561, g_loss: 2.821912 D real: 0.830682, D fake: 0.087406\n",
      "Epoch [42/100], d_loss: 0.423015, g_loss: 2.996763 D real: 0.901118, D fake: 0.163926\n",
      "Epoch [42/100], d_loss: 0.396652, g_loss: 3.041828 D real: 0.839071, D fake: 0.094543\n",
      "Epoch [42/100], d_loss: 0.636365, g_loss: 2.997936 D real: 0.850903, D fake: 0.237736\n",
      "Epoch [43/100], d_loss: 0.362261, g_loss: 4.907370 D real: 0.865504, D fake: 0.077887\n",
      "Epoch [43/100], d_loss: 0.410157, g_loss: 4.275436 D real: 0.853473, D fake: 0.105913\n",
      "Epoch [43/100], d_loss: 0.375915, g_loss: 2.962760 D real: 0.881048, D fake: 0.142092\n",
      "Epoch [43/100], d_loss: 0.563710, g_loss: 3.790210 D real: 0.796609, D fake: 0.110659\n",
      "Epoch [44/100], d_loss: 0.811823, g_loss: 3.375547 D real: 0.733302, D fake: 0.106366\n",
      "Epoch [44/100], d_loss: 0.607826, g_loss: 2.650352 D real: 0.909943, D fake: 0.274722\n",
      "Epoch [44/100], d_loss: 0.619629, g_loss: 3.809606 D real: 0.815407, D fake: 0.161103\n",
      "Epoch [44/100], d_loss: 0.510541, g_loss: 4.079297 D real: 0.838114, D fake: 0.128516\n",
      "Epoch [45/100], d_loss: 0.457870, g_loss: 2.790949 D real: 0.866118, D fake: 0.175861\n",
      "Epoch [45/100], d_loss: 0.455409, g_loss: 2.914030 D real: 0.850563, D fake: 0.135284\n",
      "Epoch [45/100], d_loss: 0.555252, g_loss: 3.083219 D real: 0.823809, D fake: 0.126972\n",
      "Epoch [45/100], d_loss: 0.311526, g_loss: 2.798458 D real: 0.893167, D fake: 0.125405\n",
      "Epoch [46/100], d_loss: 0.281950, g_loss: 3.762323 D real: 0.913326, D fake: 0.123842\n",
      "Epoch [46/100], d_loss: 0.464379, g_loss: 3.343500 D real: 0.898970, D fake: 0.212774\n",
      "Epoch [46/100], d_loss: 0.485427, g_loss: 3.427680 D real: 0.852032, D fake: 0.150865\n",
      "Epoch [46/100], d_loss: 0.390185, g_loss: 3.021165 D real: 0.833538, D fake: 0.090312\n",
      "Epoch [47/100], d_loss: 0.566178, g_loss: 3.571424 D real: 0.787414, D fake: 0.134980\n",
      "Epoch [47/100], d_loss: 0.676912, g_loss: 2.230898 D real: 0.791458, D fake: 0.164281\n",
      "Epoch [47/100], d_loss: 0.678475, g_loss: 2.504009 D real: 0.800439, D fake: 0.191554\n",
      "Epoch [47/100], d_loss: 0.516655, g_loss: 2.846357 D real: 0.814698, D fake: 0.151765\n",
      "Epoch [48/100], d_loss: 0.628961, g_loss: 2.558710 D real: 0.827433, D fake: 0.219118\n",
      "Epoch [48/100], d_loss: 0.496610, g_loss: 2.787764 D real: 0.854217, D fake: 0.172823\n",
      "Epoch [48/100], d_loss: 0.584492, g_loss: 2.718561 D real: 0.879209, D fake: 0.243885\n",
      "Epoch [48/100], d_loss: 0.647695, g_loss: 3.644845 D real: 0.731890, D fake: 0.076594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], d_loss: 0.704936, g_loss: 2.901541 D real: 0.832852, D fake: 0.239864\n",
      "Epoch [49/100], d_loss: 0.452876, g_loss: 3.441339 D real: 0.825948, D fake: 0.095942\n",
      "Epoch [49/100], d_loss: 0.619574, g_loss: 2.393365 D real: 0.781770, D fake: 0.181856\n",
      "Epoch [49/100], d_loss: 0.536264, g_loss: 2.736376 D real: 0.800440, D fake: 0.132543\n",
      "Epoch [50/100], d_loss: 0.537762, g_loss: 2.226238 D real: 0.903118, D fake: 0.274597\n",
      "Epoch [50/100], d_loss: 0.852824, g_loss: 2.224986 D real: 0.853746, D fake: 0.351694\n",
      "Epoch [50/100], d_loss: 0.412315, g_loss: 2.483872 D real: 0.877988, D fake: 0.147682\n",
      "Epoch [50/100], d_loss: 0.404211, g_loss: 3.341721 D real: 0.883285, D fake: 0.168896\n",
      "Epoch [51/100], d_loss: 0.412401, g_loss: 2.640524 D real: 0.862663, D fake: 0.158232\n",
      "Epoch [51/100], d_loss: 0.479909, g_loss: 2.896540 D real: 0.851526, D fake: 0.150938\n",
      "Epoch [51/100], d_loss: 0.550382, g_loss: 2.536888 D real: 0.828847, D fake: 0.144185\n",
      "Epoch [51/100], d_loss: 0.665353, g_loss: 2.700093 D real: 0.754672, D fake: 0.105270\n",
      "Epoch [52/100], d_loss: 0.490073, g_loss: 2.257196 D real: 0.882226, D fake: 0.191338\n",
      "Epoch [52/100], d_loss: 0.681102, g_loss: 3.464189 D real: 0.770134, D fake: 0.127234\n",
      "Epoch [52/100], d_loss: 0.542041, g_loss: 2.326103 D real: 0.822188, D fake: 0.139609\n",
      "Epoch [52/100], d_loss: 0.560542, g_loss: 2.852735 D real: 0.838660, D fake: 0.180339\n",
      "Epoch [53/100], d_loss: 0.497459, g_loss: 2.361952 D real: 0.827666, D fake: 0.177001\n",
      "Epoch [53/100], d_loss: 0.801449, g_loss: 2.725773 D real: 0.728924, D fake: 0.148319\n",
      "Epoch [53/100], d_loss: 0.634042, g_loss: 2.474663 D real: 0.842074, D fake: 0.269485\n",
      "Epoch [53/100], d_loss: 0.553427, g_loss: 3.355919 D real: 0.814728, D fake: 0.133817\n",
      "Epoch [54/100], d_loss: 0.615234, g_loss: 3.376224 D real: 0.841725, D fake: 0.241459\n",
      "Epoch [54/100], d_loss: 0.441310, g_loss: 2.691649 D real: 0.853062, D fake: 0.141104\n",
      "Epoch [54/100], d_loss: 0.579825, g_loss: 2.854517 D real: 0.792215, D fake: 0.156901\n",
      "Epoch [54/100], d_loss: 0.712948, g_loss: 2.806430 D real: 0.803613, D fake: 0.222165\n",
      "Epoch [55/100], d_loss: 0.451719, g_loss: 2.632698 D real: 0.898883, D fake: 0.222268\n",
      "Epoch [55/100], d_loss: 0.530906, g_loss: 3.086033 D real: 0.859639, D fake: 0.177146\n",
      "Epoch [55/100], d_loss: 0.552415, g_loss: 2.580405 D real: 0.860373, D fake: 0.208654\n",
      "Epoch [55/100], d_loss: 0.555471, g_loss: 2.838994 D real: 0.818353, D fake: 0.189888\n",
      "Epoch [56/100], d_loss: 0.614884, g_loss: 2.541747 D real: 0.773911, D fake: 0.163134\n",
      "Epoch [56/100], d_loss: 0.520729, g_loss: 3.279228 D real: 0.820323, D fake: 0.141759\n",
      "Epoch [56/100], d_loss: 0.569439, g_loss: 3.093745 D real: 0.827773, D fake: 0.155468\n",
      "Epoch [56/100], d_loss: 0.804995, g_loss: 2.089415 D real: 0.801680, D fake: 0.260284\n",
      "Epoch [57/100], d_loss: 0.599218, g_loss: 2.703981 D real: 0.823334, D fake: 0.209596\n",
      "Epoch [57/100], d_loss: 0.782971, g_loss: 2.286196 D real: 0.798897, D fake: 0.237870\n",
      "Epoch [57/100], d_loss: 0.600582, g_loss: 2.474115 D real: 0.751303, D fake: 0.098143\n",
      "Epoch [57/100], d_loss: 0.548802, g_loss: 2.156906 D real: 0.867455, D fake: 0.200924\n",
      "Epoch [58/100], d_loss: 0.585780, g_loss: 2.919468 D real: 0.779899, D fake: 0.124311\n",
      "Epoch [58/100], d_loss: 0.634086, g_loss: 2.412694 D real: 0.821980, D fake: 0.220951\n",
      "Epoch [58/100], d_loss: 0.648336, g_loss: 3.273396 D real: 0.767592, D fake: 0.142154\n",
      "Epoch [58/100], d_loss: 0.450686, g_loss: 2.352568 D real: 0.820904, D fake: 0.130439\n",
      "Epoch [59/100], d_loss: 0.602713, g_loss: 3.131560 D real: 0.755186, D fake: 0.128640\n",
      "Epoch [59/100], d_loss: 0.689488, g_loss: 2.248833 D real: 0.802553, D fake: 0.232599\n",
      "Epoch [59/100], d_loss: 0.700314, g_loss: 2.390604 D real: 0.846711, D fake: 0.290284\n",
      "Epoch [59/100], d_loss: 0.823160, g_loss: 2.183578 D real: 0.799664, D fake: 0.303288\n",
      "Epoch [60/100], d_loss: 0.590843, g_loss: 2.231046 D real: 0.779700, D fake: 0.160495\n",
      "Epoch [60/100], d_loss: 0.564549, g_loss: 3.199874 D real: 0.904560, D fake: 0.283174\n",
      "Epoch [60/100], d_loss: 0.674924, g_loss: 2.439026 D real: 0.786946, D fake: 0.201342\n",
      "Epoch [60/100], d_loss: 0.457105, g_loss: 2.507396 D real: 0.848113, D fake: 0.164905\n",
      "Epoch [61/100], d_loss: 0.722492, g_loss: 2.367691 D real: 0.769318, D fake: 0.228132\n",
      "Epoch [61/100], d_loss: 0.396514, g_loss: 2.721019 D real: 0.863217, D fake: 0.142083\n",
      "Epoch [61/100], d_loss: 0.662524, g_loss: 2.540176 D real: 0.771886, D fake: 0.197200\n",
      "Epoch [61/100], d_loss: 0.671301, g_loss: 2.256078 D real: 0.784792, D fake: 0.187924\n",
      "Epoch [62/100], d_loss: 0.595018, g_loss: 2.934736 D real: 0.797715, D fake: 0.181823\n",
      "Epoch [62/100], d_loss: 0.551971, g_loss: 2.113917 D real: 0.835663, D fake: 0.201739\n",
      "Epoch [62/100], d_loss: 0.622734, g_loss: 2.361494 D real: 0.855087, D fake: 0.248834\n",
      "Epoch [62/100], d_loss: 0.490474, g_loss: 2.714149 D real: 0.824181, D fake: 0.149449\n",
      "Epoch [63/100], d_loss: 0.680593, g_loss: 1.907336 D real: 0.860804, D fake: 0.298258\n",
      "Epoch [63/100], d_loss: 0.837829, g_loss: 2.491504 D real: 0.768504, D fake: 0.260129\n",
      "Epoch [63/100], d_loss: 0.563215, g_loss: 2.259662 D real: 0.820375, D fake: 0.182603\n",
      "Epoch [63/100], d_loss: 0.421726, g_loss: 3.012917 D real: 0.850946, D fake: 0.143790\n",
      "Epoch [64/100], d_loss: 0.470185, g_loss: 2.570023 D real: 0.871031, D fake: 0.208245\n",
      "Epoch [64/100], d_loss: 0.952677, g_loss: 2.241083 D real: 0.722951, D fake: 0.210254\n",
      "Epoch [64/100], d_loss: 0.724973, g_loss: 2.539075 D real: 0.751735, D fake: 0.179689\n",
      "Epoch [64/100], d_loss: 0.643117, g_loss: 2.662000 D real: 0.828671, D fake: 0.212775\n",
      "Epoch [65/100], d_loss: 0.794017, g_loss: 2.486488 D real: 0.688398, D fake: 0.144488\n",
      "Epoch [65/100], d_loss: 0.523267, g_loss: 2.560911 D real: 0.841427, D fake: 0.190571\n",
      "Epoch [65/100], d_loss: 0.705704, g_loss: 2.125958 D real: 0.790774, D fake: 0.227356\n",
      "Epoch [65/100], d_loss: 0.504411, g_loss: 2.244761 D real: 0.884449, D fake: 0.222598\n",
      "Epoch [66/100], d_loss: 0.562162, g_loss: 2.615235 D real: 0.824502, D fake: 0.226558\n",
      "Epoch [66/100], d_loss: 0.636068, g_loss: 1.710403 D real: 0.833716, D fake: 0.258278\n",
      "Epoch [66/100], d_loss: 0.792251, g_loss: 2.102362 D real: 0.831614, D fake: 0.320307\n",
      "Epoch [66/100], d_loss: 0.924524, g_loss: 2.365788 D real: 0.694373, D fake: 0.156210\n",
      "Epoch [67/100], d_loss: 0.435416, g_loss: 2.412655 D real: 0.865761, D fake: 0.177846\n",
      "Epoch [67/100], d_loss: 0.769558, g_loss: 1.769028 D real: 0.751126, D fake: 0.217662\n",
      "Epoch [67/100], d_loss: 0.660185, g_loss: 2.242208 D real: 0.778748, D fake: 0.206308\n",
      "Epoch [67/100], d_loss: 0.534340, g_loss: 2.224072 D real: 0.857686, D fake: 0.231175\n",
      "Epoch [68/100], d_loss: 0.577574, g_loss: 2.493431 D real: 0.861731, D fake: 0.248368\n",
      "Epoch [68/100], d_loss: 0.723886, g_loss: 2.400090 D real: 0.828988, D fake: 0.281533\n",
      "Epoch [68/100], d_loss: 0.669505, g_loss: 2.997233 D real: 0.799475, D fake: 0.184628\n",
      "Epoch [68/100], d_loss: 0.614531, g_loss: 2.042605 D real: 0.804897, D fake: 0.198332\n",
      "Epoch [69/100], d_loss: 0.492292, g_loss: 2.971114 D real: 0.802402, D fake: 0.142903\n",
      "Epoch [69/100], d_loss: 0.767208, g_loss: 2.287004 D real: 0.808901, D fake: 0.259822\n",
      "Epoch [69/100], d_loss: 0.702861, g_loss: 1.971214 D real: 0.742339, D fake: 0.154723\n",
      "Epoch [69/100], d_loss: 0.898799, g_loss: 2.712288 D real: 0.698859, D fake: 0.218114\n",
      "Epoch [70/100], d_loss: 0.829592, g_loss: 1.912473 D real: 0.732778, D fake: 0.216573\n",
      "Epoch [70/100], d_loss: 0.573956, g_loss: 2.678911 D real: 0.857172, D fake: 0.233219\n",
      "Epoch [70/100], d_loss: 0.547264, g_loss: 2.431780 D real: 0.794838, D fake: 0.175433\n",
      "Epoch [70/100], d_loss: 0.744977, g_loss: 2.192952 D real: 0.825395, D fake: 0.307027\n",
      "Epoch [71/100], d_loss: 0.640363, g_loss: 2.124524 D real: 0.819052, D fake: 0.263439\n",
      "Epoch [71/100], d_loss: 0.904713, g_loss: 1.653226 D real: 0.681583, D fake: 0.189228\n",
      "Epoch [71/100], d_loss: 0.664812, g_loss: 2.520947 D real: 0.778056, D fake: 0.195571\n",
      "Epoch [71/100], d_loss: 0.694709, g_loss: 2.232291 D real: 0.728161, D fake: 0.169907\n",
      "Epoch [72/100], d_loss: 0.670918, g_loss: 2.359243 D real: 0.848021, D fake: 0.279437\n",
      "Epoch [72/100], d_loss: 0.803706, g_loss: 2.057060 D real: 0.717051, D fake: 0.199357\n",
      "Epoch [72/100], d_loss: 0.674580, g_loss: 2.462642 D real: 0.778643, D fake: 0.217860\n",
      "Epoch [72/100], d_loss: 0.618969, g_loss: 2.520961 D real: 0.839853, D fake: 0.207829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], d_loss: 0.625800, g_loss: 2.762475 D real: 0.790383, D fake: 0.185025\n",
      "Epoch [73/100], d_loss: 0.726915, g_loss: 1.846308 D real: 0.751871, D fake: 0.202921\n",
      "Epoch [73/100], d_loss: 0.747400, g_loss: 2.000257 D real: 0.776225, D fake: 0.253975\n",
      "Epoch [73/100], d_loss: 0.777153, g_loss: 2.332372 D real: 0.753980, D fake: 0.231522\n",
      "Epoch [74/100], d_loss: 0.795353, g_loss: 2.410901 D real: 0.752318, D fake: 0.207912\n",
      "Epoch [74/100], d_loss: 0.769414, g_loss: 2.167787 D real: 0.789959, D fake: 0.318568\n",
      "Epoch [74/100], d_loss: 0.632812, g_loss: 2.801226 D real: 0.756181, D fake: 0.147025\n",
      "Epoch [74/100], d_loss: 0.484532, g_loss: 3.162210 D real: 0.842913, D fake: 0.150591\n",
      "Epoch [75/100], d_loss: 0.735673, g_loss: 1.822918 D real: 0.772775, D fake: 0.230203\n",
      "Epoch [75/100], d_loss: 0.861266, g_loss: 1.780242 D real: 0.750698, D fake: 0.270627\n",
      "Epoch [75/100], d_loss: 0.538852, g_loss: 2.000544 D real: 0.847184, D fake: 0.217492\n",
      "Epoch [75/100], d_loss: 0.728914, g_loss: 2.147697 D real: 0.811675, D fake: 0.284239\n",
      "Epoch [76/100], d_loss: 0.793400, g_loss: 2.688862 D real: 0.701904, D fake: 0.169732\n",
      "Epoch [76/100], d_loss: 0.710720, g_loss: 1.636289 D real: 0.803710, D fake: 0.245624\n",
      "Epoch [76/100], d_loss: 0.878201, g_loss: 1.628105 D real: 0.821562, D fake: 0.359484\n",
      "Epoch [76/100], d_loss: 0.574878, g_loss: 3.085488 D real: 0.836369, D fake: 0.220676\n",
      "Epoch [77/100], d_loss: 0.772984, g_loss: 2.164977 D real: 0.843325, D fake: 0.321041\n",
      "Epoch [77/100], d_loss: 0.718034, g_loss: 2.283172 D real: 0.732687, D fake: 0.176834\n",
      "Epoch [77/100], d_loss: 0.690384, g_loss: 2.212525 D real: 0.779148, D fake: 0.218755\n",
      "Epoch [77/100], d_loss: 0.673173, g_loss: 2.520568 D real: 0.811238, D fake: 0.231736\n",
      "Epoch [78/100], d_loss: 0.607444, g_loss: 2.812399 D real: 0.773463, D fake: 0.156234\n",
      "Epoch [78/100], d_loss: 0.639529, g_loss: 2.082974 D real: 0.839938, D fake: 0.265888\n",
      "Epoch [78/100], d_loss: 0.631652, g_loss: 2.786550 D real: 0.741078, D fake: 0.157991\n",
      "Epoch [78/100], d_loss: 0.583098, g_loss: 2.120481 D real: 0.823711, D fake: 0.232384\n",
      "Epoch [79/100], d_loss: 0.784603, g_loss: 2.020871 D real: 0.783143, D fake: 0.272868\n",
      "Epoch [79/100], d_loss: 0.802206, g_loss: 2.233742 D real: 0.784756, D fake: 0.287250\n",
      "Epoch [79/100], d_loss: 0.764996, g_loss: 1.893383 D real: 0.713515, D fake: 0.185420\n",
      "Epoch [79/100], d_loss: 0.627716, g_loss: 2.122441 D real: 0.806370, D fake: 0.215892\n",
      "Epoch [80/100], d_loss: 0.595717, g_loss: 2.566977 D real: 0.795427, D fake: 0.194581\n",
      "Epoch [80/100], d_loss: 0.832870, g_loss: 1.647428 D real: 0.788178, D fake: 0.298702\n",
      "Epoch [80/100], d_loss: 0.764344, g_loss: 1.675594 D real: 0.777886, D fake: 0.285296\n",
      "Epoch [80/100], d_loss: 0.602564, g_loss: 2.313890 D real: 0.759831, D fake: 0.129800\n",
      "Epoch [81/100], d_loss: 0.497513, g_loss: 2.215135 D real: 0.790290, D fake: 0.129029\n",
      "Epoch [81/100], d_loss: 0.766009, g_loss: 1.689286 D real: 0.735653, D fake: 0.202143\n",
      "Epoch [81/100], d_loss: 0.849090, g_loss: 1.984019 D real: 0.683541, D fake: 0.192583\n",
      "Epoch [81/100], d_loss: 0.783852, g_loss: 1.630722 D real: 0.791690, D fake: 0.282837\n",
      "Epoch [82/100], d_loss: 0.716271, g_loss: 1.429972 D real: 0.742830, D fake: 0.194798\n",
      "Epoch [82/100], d_loss: 0.890285, g_loss: 1.992628 D real: 0.691120, D fake: 0.226116\n",
      "Epoch [82/100], d_loss: 0.609094, g_loss: 2.049385 D real: 0.764344, D fake: 0.169533\n",
      "Epoch [82/100], d_loss: 0.733470, g_loss: 2.129327 D real: 0.757499, D fake: 0.218891\n",
      "Epoch [83/100], d_loss: 0.792840, g_loss: 1.853562 D real: 0.698701, D fake: 0.212129\n",
      "Epoch [83/100], d_loss: 0.484763, g_loss: 2.321822 D real: 0.848499, D fake: 0.173845\n",
      "Epoch [83/100], d_loss: 0.763933, g_loss: 2.042179 D real: 0.754788, D fake: 0.240581\n",
      "Epoch [83/100], d_loss: 0.634248, g_loss: 2.297203 D real: 0.756205, D fake: 0.185364\n",
      "Epoch [84/100], d_loss: 0.781096, g_loss: 1.971991 D real: 0.730610, D fake: 0.230654\n",
      "Epoch [84/100], d_loss: 0.734048, g_loss: 2.607094 D real: 0.782618, D fake: 0.245179\n",
      "Epoch [84/100], d_loss: 0.571847, g_loss: 2.707074 D real: 0.786259, D fake: 0.157686\n",
      "Epoch [84/100], d_loss: 0.652199, g_loss: 2.303676 D real: 0.779352, D fake: 0.231763\n",
      "Epoch [85/100], d_loss: 0.877319, g_loss: 2.260842 D real: 0.717910, D fake: 0.230066\n",
      "Epoch [85/100], d_loss: 0.784865, g_loss: 2.569624 D real: 0.728396, D fake: 0.161587\n",
      "Epoch [85/100], d_loss: 0.747724, g_loss: 1.947697 D real: 0.733820, D fake: 0.214209\n",
      "Epoch [85/100], d_loss: 0.777845, g_loss: 2.094553 D real: 0.827608, D fake: 0.335257\n",
      "Epoch [86/100], d_loss: 0.615069, g_loss: 2.502259 D real: 0.763394, D fake: 0.143264\n",
      "Epoch [86/100], d_loss: 0.859848, g_loss: 1.458390 D real: 0.736882, D fake: 0.263626\n",
      "Epoch [86/100], d_loss: 0.804613, g_loss: 2.136364 D real: 0.777686, D fake: 0.264224\n",
      "Epoch [86/100], d_loss: 0.764992, g_loss: 1.996842 D real: 0.777092, D fake: 0.255900\n",
      "Epoch [87/100], d_loss: 0.830921, g_loss: 1.924789 D real: 0.745239, D fake: 0.274586\n",
      "Epoch [87/100], d_loss: 0.502273, g_loss: 2.563081 D real: 0.862377, D fake: 0.212959\n",
      "Epoch [87/100], d_loss: 0.856006, g_loss: 2.206710 D real: 0.673888, D fake: 0.177075\n",
      "Epoch [87/100], d_loss: 0.713211, g_loss: 2.291088 D real: 0.737127, D fake: 0.192102\n",
      "Epoch [88/100], d_loss: 0.796894, g_loss: 2.036736 D real: 0.720805, D fake: 0.229706\n",
      "Epoch [88/100], d_loss: 0.729450, g_loss: 1.836889 D real: 0.793000, D fake: 0.288566\n",
      "Epoch [88/100], d_loss: 0.800124, g_loss: 1.624892 D real: 0.724358, D fake: 0.246669\n",
      "Epoch [88/100], d_loss: 0.561176, g_loss: 2.438965 D real: 0.799913, D fake: 0.185776\n",
      "Epoch [89/100], d_loss: 0.907929, g_loss: 1.833304 D real: 0.702922, D fake: 0.244617\n",
      "Epoch [89/100], d_loss: 0.851022, g_loss: 1.707688 D real: 0.704610, D fake: 0.217015\n",
      "Epoch [89/100], d_loss: 0.636167, g_loss: 2.121022 D real: 0.776681, D fake: 0.196552\n",
      "Epoch [89/100], d_loss: 0.657743, g_loss: 2.301291 D real: 0.828071, D fake: 0.281652\n",
      "Epoch [90/100], d_loss: 0.630605, g_loss: 2.354911 D real: 0.797199, D fake: 0.226037\n",
      "Epoch [90/100], d_loss: 0.658923, g_loss: 2.525108 D real: 0.784354, D fake: 0.211423\n",
      "Epoch [90/100], d_loss: 0.708875, g_loss: 2.006889 D real: 0.734574, D fake: 0.187070\n",
      "Epoch [90/100], d_loss: 0.670283, g_loss: 2.325207 D real: 0.781218, D fake: 0.227068\n",
      "Epoch [91/100], d_loss: 0.866719, g_loss: 1.898873 D real: 0.764710, D fake: 0.308187\n",
      "Epoch [91/100], d_loss: 0.902468, g_loss: 1.663007 D real: 0.728806, D fake: 0.284368\n",
      "Epoch [91/100], d_loss: 0.622025, g_loss: 2.489467 D real: 0.784846, D fake: 0.198288\n",
      "Epoch [91/100], d_loss: 0.662604, g_loss: 1.901472 D real: 0.781090, D fake: 0.238220\n",
      "Epoch [92/100], d_loss: 0.787485, g_loss: 2.137385 D real: 0.701938, D fake: 0.205355\n",
      "Epoch [92/100], d_loss: 0.693079, g_loss: 2.096883 D real: 0.785565, D fake: 0.247752\n",
      "Epoch [92/100], d_loss: 0.779496, g_loss: 2.429430 D real: 0.724793, D fake: 0.198792\n",
      "Epoch [92/100], d_loss: 0.782531, g_loss: 1.880901 D real: 0.745025, D fake: 0.246371\n"
     ]
    }
   ],
   "source": [
    "D = discriminator()\n",
    "G = generator()\n",
    "if torch.cuda.is_available():\n",
    "    D = D.cuda()\n",
    "    G = G.cuda()\n",
    "# Binary cross entropy loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0003)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0003)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    for i, (img, _) in enumerate(dataloader):\n",
    "        num_img = img.size(0)\n",
    "        # =================train discriminator\n",
    "        img = img.view(num_img, -1)\n",
    "        real_img = Variable(img).cuda()\n",
    "        real_label = Variable(torch.ones(num_img)).cuda()\n",
    "        fake_label = Variable(torch.zeros(num_img)).cuda()\n",
    "\n",
    "        # compute loss of real_img\n",
    "        real_out = D(real_img)\n",
    "        d_loss_real = criterion(real_out, real_label)\n",
    "        real_scores = real_out  # closer to 1 means better\n",
    "\n",
    "        # compute loss of fake_img\n",
    "        z = Variable(torch.randn(num_img, z_dimension)).cuda()\n",
    "        fake_img = G(z)\n",
    "        fake_out = D(fake_img)\n",
    "        d_loss_fake = criterion(fake_out, fake_label)\n",
    "        fake_scores = fake_out  # closer to 0 means better\n",
    "\n",
    "        # bp and optimize\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_optimizer.zero_grad()\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "        \n",
    "        # ===============train generator\n",
    "        # compute loss of fake_img\n",
    "        z = Variable(torch.randn(num_img, z_dimension)).cuda()\n",
    "        fake_img = G(z)\n",
    "        output = D(fake_img)\n",
    "        g_loss = criterion(output, real_label)\n",
    "        \n",
    "        # bp and optimize\n",
    "        g_optimizer.zero_grad()\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], d_loss: {:.6f}, g_loss: {:.6f} '\n",
    "                  'D real: {:.6f}, D fake: {:.6f}'.format(\n",
    "                      epoch, num_epoch, d_loss.data[0], g_loss.data[0],\n",
    "                      real_scores.data.mean(), fake_scores.data.mean()))\n",
    "    if epoch == 0:\n",
    "        real_images = to_img(real_img.cpu().data)\n",
    "        save_image(real_images, './img/real_images.png')\n",
    "\n",
    "    fake_images = to_img(fake_img.cpu().data)\n",
    "    save_image(fake_images, './img/fake_images-{}.png'.format(epoch + 1))\n",
    "\n",
    "torch.save(G.state_dict(), './generator.pth')\n",
    "torch.save(D.state_dict(), './discriminator.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
